{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T10:32:23.316625Z",
     "start_time": "2020-10-03T10:32:04.850782Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import requests, pandas as pd\n",
    "import numpy as np\n",
    "import colorsys, os, math\n",
    "from matplotlib import colors\n",
    "import time, sqlite3, datetime\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T10:32:23.385274Z",
     "start_time": "2020-10-03T10:32:23.318276Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parseDF(url, json_column, drop_columns):   \n",
    "    \n",
    "    # fetch json\n",
    "    allIndiaData = requests.get(url).json()\n",
    "    \n",
    "    # extract data from json into dataframe\n",
    "    stateCoronaDfs=[]\n",
    "    for statename, stateData in allIndiaData.items():\n",
    "        \n",
    "        stateCoronaDf=pd.DataFrame(stateData)\n",
    "        # normalize json columns and split them into individual columns\n",
    "        normalizedColumns=pd.json_normalize(stateCoronaDf[json_column])\n",
    "        stateCoronaDf.drop(columns=[json_column], inplace=True)\n",
    "        normalizedColumns.index=stateCoronaDf.index\n",
    "        stateCoronaDf[normalizedColumns.columns]=normalizedColumns[normalizedColumns.columns]\n",
    "        if len(drop_columns):\n",
    "            stateCoronaDf.drop(columns=drop_columns, inplace=True)\n",
    "        stateCoronaDf.statecode=statename\n",
    "        stateCoronaDfs.append(stateCoronaDf)    \n",
    "    \n",
    "    # final dataframe\n",
    "    coronaDf=pd.concat(stateCoronaDfs)\n",
    "    coronaDf['Constituency']=coronaDf.index\n",
    "    coronaDf.reset_index(inplace=True, drop=True)    \n",
    "    \n",
    "    coronaDf['Constituency']=coronaDf['Constituency'].str.lower()\n",
    "    coronaDf['statecode']=coronaDf['statecode'].str.lower()\n",
    "    \n",
    "#     coronaDf.set_index([\"statecode\", \"Constituency\"], inplace = True,\n",
    "#                             append = False, drop = True, verify_integrity=True)\n",
    "\n",
    "\n",
    "    # drop row if active case is negative, nan or infinity\n",
    "    coronaDf=coronaDf[coronaDf.active>=0]\n",
    "    coronaDf=coronaDf[np.isfinite(coronaDf.active)]\n",
    "    coronaDf=coronaDf[~coronaDf.active.isna()]\n",
    "    \n",
    "    # coronaDf.to_excel('hack.xlsx')\n",
    "    return coronaDf\n",
    "\n",
    "\n",
    "def _get_best_k(Ks, Costs):\n",
    "    \n",
    "    # elbow-method for best K selection\n",
    "    points=np.array(list(zip(Ks, Costs)))\n",
    "    A=points[0]\n",
    "    B=points[-1]    \n",
    "    distFromLine_AB = [np.linalg.norm(np.cross(B-A, A-point))/np.linalg.norm(B-A) \n",
    "                 for point in points]\n",
    "    \n",
    "    return int(Ks[np.argmax(distFromLine_AB)])\n",
    "\n",
    "\n",
    "def choose_colors(num_colors):\n",
    "    \n",
    "    colors=[]\n",
    "    for i in np.arange(0., 360., 360. / num_colors):\n",
    "        hue = i/360.\n",
    "        lightness = 0.85\n",
    "        saturation = (90 + np.random.rand() * 10)/100.\n",
    "        colors.append(colorsys.hls_to_rgb(hue, lightness, saturation))\n",
    "    return np.array(colors)\n",
    "\n",
    "\n",
    "def cluster_risk(risks, max_cluster):\n",
    "    \n",
    "    risks=np.array(risks).reshape(-1, 1)    \n",
    "    Ks=list(range(2, max_cluster+1))\n",
    "    Costs=[]    \n",
    "    KMeansModels={}\n",
    "\n",
    "    # dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\n",
    "    for k in Ks:\n",
    "        classifier = KMeans(n_clusters = k)\n",
    "        classifier.fit(risks)\n",
    "        Costs.append(classifier.inertia_)\n",
    "        KMeansModels[k]=classifier\n",
    "\n",
    "    k_optimum=_get_best_k(Ks, Costs)\n",
    "    colors=choose_colors(k_optimum)\n",
    "    labels=KMeansModels[k_optimum].predict(risks)\n",
    "    \n",
    "    return colors[labels], KMeansModels[k_optimum].cluster_centers_[labels]\n",
    "\n",
    "\n",
    "def normalizeColumns(col):\n",
    "    \n",
    "    loglog=np.log2(np.array(col)+1)\n",
    "    normalized = preprocessing.MinMaxScaler(feature_range=(0.3, 0.9)).fit_transform(\n",
    "        preprocessing.StandardScaler().fit_transform(loglog.reshape(-1, 1)))\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def rankClusters(arr):\n",
    "    # assign priority to cluster means of active cases\n",
    "    clusterCenters=np.unique(arr).tolist()\n",
    "    priorities=list(range(len(clusterCenters)))\n",
    "    priorityDict=dict(list(zip(clusterCenters, priorities)))\n",
    "    return np.array([priorityDict[a] for a in arr])\n",
    "\n",
    "calcrisk=lambda pop, active: active*np.log10(pop+1)\n",
    "\n",
    "def assignPriority(ranks, populations, actives):\n",
    "    \n",
    "    allRows=pd.DataFrame(zip(ranks, populations, actives), \n",
    "                    columns=[\"rank\", \"population\", \"active\"])    \n",
    "    allRows['risk']=calcrisk(np.array(populations), np.array(actives))\n",
    "    allRows=allRows[['rank', 'risk']]\n",
    "    \n",
    "    normalizers={rank:preprocessing.MinMaxScaler(feature_range=(0.0, 0.5)).fit(riskDf[['risk']]) \n",
    "                 for rank, riskDf in allRows.groupby('rank')}\n",
    "    \n",
    "#     allRows['Population']=populations\n",
    "#     allRows['active']=actives\n",
    "#     allRows['prior']=(allRows['rank'] + allRows.apply(lambda rowval: \n",
    "#         normalizers[rowval[0]].transform([[rowval[1]]])[0][0], axis=1)).tolist()   \n",
    "#     allRows.to_csv('debugger.csv')\n",
    "    \n",
    "    return (allRows['rank'] + allRows.apply(lambda rowval: \n",
    "        normalizers[rowval[0]].transform([[rowval[1]]])[0][0], axis=1)).tolist()   \n",
    "\n",
    "\n",
    "def getDistrictPopulationDf(censusFile):\n",
    "    # get population data from census\n",
    "    df=pd.read_csv(censusFile)\n",
    "    df['District name']=df['District name'].str.lower()\n",
    "    df['State name']=df['State name'].str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def fillpopulationData(coronaDf, censusDf):\n",
    "    # fill population data from census data to corona df\n",
    "    def PopulationOfStateNDistrict(state, district):\n",
    "        valdf=censusDf[(censusDf['District name']==district) & (censusDf['State name']==state)]\n",
    "        if valdf.empty:\n",
    "            return None\n",
    "        return valdf.Population.tolist()[0]\n",
    "    \n",
    "    # get population\n",
    "    populationWithNA = pd.Series(coronaDf[['statecode', 'Constituency']].apply(\n",
    "        lambda row : PopulationOfStateNDistrict(row[0], row[1]), axis=1))\n",
    "    \n",
    "    # replace unavailable population with remaining population for corresponding state\n",
    "    populationOfState={statename:stateDf.Population.sum() \n",
    "        for statename, stateDf in censusDf.groupby('State name')}\n",
    "    \n",
    "    nullCountOfState={statename:len(stateDf)\n",
    "        for statename, stateDf in coronaDf[populationWithNA.isna()].groupby('statecode')}   \n",
    "    \n",
    "    meanvalToFillForState={statename:populationOfState.get(statename, 0)//nullCount \n",
    "        for statename, nullCount in \n",
    "                nullCountOfState.items() if nullCount}\n",
    "    populationwithZeroVal=pd.Series([p if not(math.isnan(p)) \n",
    "     else meanvalToFillForState[coronaDf.statecode.iloc[i]] for i, p in enumerate(populationWithNA)])\n",
    "    meanpop=populationwithZeroVal[populationwithZeroVal>0].mean()\n",
    "    populationwithZeroVal=populationwithZeroVal.replace(0, int(meanpop))\n",
    "    return populationwithZeroVal.tolist()\n",
    "\n",
    "\n",
    "def dataProcessing(intervalInMinutes, database, max_cluster, \n",
    "                   API, censusFile, normalize_columns=[]):\n",
    "    \n",
    "    global globalDfhandler\n",
    "    Pass=0\n",
    "    while True:        \n",
    "        # parse df\n",
    "        coronaDf=parseDF(url=API, json_column='districtData', \n",
    "                        drop_columns=['notes', 'delta.confirmed', 'delta.deceased', 'delta.recovered'])\n",
    "        \n",
    "        # clustering\n",
    "        activeCases = coronaDf.active.to_numpy(dtype='float64')\n",
    "        cololabels, centers = cluster_risk(activeCases, max_cluster=max_cluster)\n",
    "                \n",
    "        # add more columns\n",
    "        for col in normalize_columns:\n",
    "            coronaDf[f'{col}-normalized'] = normalizeColumns(coronaDf[col])\n",
    "            \n",
    "        # handle population data\n",
    "        censusDf=getDistrictPopulationDf(censusFile)\n",
    "        coronaDf['Population']=fillpopulationData(coronaDf, censusDf)\n",
    "        \n",
    "        # assign priority\n",
    "        ranks=rankClusters(centers.reshape(-1))\n",
    "        coronaDf['priority']=ranks\n",
    "        coronaDf['tuned-priority']=assignPriority(\n",
    "            coronaDf['priority'].tolist(), coronaDf['Population'].tolist(), coronaDf['active'].tolist())\n",
    "        \n",
    "        # cluster-color\n",
    "        darknessForCluster=preprocessing.MinMaxScaler(feature_range=(0, 0.7)\n",
    "            ).fit_transform(np.array(coronaDf['priority']).reshape(-1, 1))[:, 0]\n",
    "        darknessForSubcluster=(coronaDf['tuned-priority'].to_numpy()%1)*0.3\n",
    "        cololabels[:, 1]=1-darknessForCluster-darknessForSubcluster\n",
    "        coronaDf['color']=np.apply_along_axis(colors.to_hex, 1, cololabels)\n",
    "        \n",
    "        if not os.path.isdir(os.path.dirname(database)):\n",
    "            os.makedirs(os.path.dirname(database))\n",
    "            \n",
    "        cnx = sqlite3.connect(database)\n",
    "        coronaDf.to_sql(name='main', con=cnx, if_exists='replace')\n",
    "        cnx.close()\n",
    "        globalDfhandler=coronaDf.copy()\n",
    "        \n",
    "        try:\n",
    "            coronaDf.to_excel('debug.xlsx')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f'{datetime.datetime.now()}: {Pass+1}th updation done.')\n",
    "        Pass=Pass+1\n",
    "        time.sleep(intervalInMinutes*60)\n",
    "    \n",
    "#     plt.ylim(-10, 10)\n",
    "#     for casecount, label in zip(activeCases, labels):\n",
    "#         plt.scatter(casecount, 0.0, color=label)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T10:33:12.160302Z",
     "start_time": "2020-10-03T10:32:23.389088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-03 16:02:29.481828: 1th updation done.\n",
      "2020-10-03 16:02:44.784638: 2th updation done.\n",
      "2020-10-03 16:02:59.968238: 3th updation done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2ececb0ebed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mmax_cluster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'https://api.covid19india.org/state_district_wise.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[0mnormalize_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'active'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deceased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recovered'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'confirmed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                   censusFile='../Census Data/census-2011.csv')\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-4bbb9f1a94b1>\u001b[0m in \u001b[0;36mdataProcessing\u001b[1;34m(intervalInMinutes, database, max_cluster, API, censusFile, normalize_columns)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{datetime.datetime.now()}: {Pass+1}th updation done.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mPass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPass\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintervalInMinutes\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;31m#     plt.ylim(-10, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataProcessing(intervalInMinutes=0.2, database='../Database/corona.db', \n",
    "                   max_cluster=10, API='https://api.covid19india.org/state_district_wise.json',\n",
    "                  normalize_columns=['active', 'deceased', 'recovered', 'confirmed'],\n",
    "                  censusFile='../Census Data/census-2011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T10:33:12.164325Z",
     "start_time": "2020-10-03T10:32:04.865Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     globalDfhandler.plot(x=['tuned-priority'], y=['tuned-priority'], color=globalDfhandler.color, kind='scatter')\n",
    "    globalDfhandler.plot(y=['active-normalized'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
